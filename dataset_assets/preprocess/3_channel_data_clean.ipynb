{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the channel videos dataset (after combination), we will commence the similar cleaning techniques as used in trending dataset (percentile-based), but this time, only 10% will be cut off (those videos won't likely be trending as of Dec.2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_file_path = \"C:/Users/TKN/Downloads/New-Youtube-Scraper-v3/data/combined_channel_data.json\"\n",
    "with open(channel_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    trending_videos = json.load(f)\n",
    "\n",
    "channel_df = pd.DataFrame.from_dict(trending_videos, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17651 entries, V0CniCFbxLs to uF1YHaeAHEw\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   fetchedDate      17651 non-null  object \n",
      " 1   publishedAt      17651 non-null  object \n",
      " 2   elapsedDays      17651 non-null  float64\n",
      " 3   title            17651 non-null  object \n",
      " 4   description      17651 non-null  object \n",
      " 5   channelTitle     17651 non-null  object \n",
      " 6   tags             13662 non-null  object \n",
      " 7   category         17651 non-null  object \n",
      " 8   duration         17651 non-null  object \n",
      " 9   licensedContent  17651 non-null  bool   \n",
      " 10  viewCount        17651 non-null  int64  \n",
      " 11  avgDailyViews    17651 non-null  float64\n",
      " 12  likeCount        17651 non-null  int64  \n",
      " 13  commentCount     17651 non-null  int64  \n",
      " 14  engagementRate   17651 non-null  float64\n",
      " 15  topicCategories  17651 non-null  object \n",
      "dtypes: bool(1), float64(3), int64(3), object(9)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "channel_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`view_stat` function to view the lowest numbers across the vital categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_stats(column_name):\n",
    "    list = sorted(channel_df[column_name].tolist())\n",
    "    print(list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[112, 114, 117, 119, 136, 140, 171, 171, 173, 176]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.02, 0.02, 0.02, 0.02, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03]\n"
     ]
    }
   ],
   "source": [
    "view_stats('viewCount')\n",
    "view_stats('likeCount')\n",
    "view_stats('commentCount')\n",
    "view_stats('engagementRate')\n",
    "view_stats('avgDailyViews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`view_lowest` function to view the videos with the lowest interactions (view count, like count, comment count, average daily views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_lowest(column_name):\n",
    "    lowest_view_count_row = channel_df.loc[channel_df[column_name].idxmin()]\n",
    "    print(f\"Title: {lowest_view_count_row['title']}\")\n",
    "    print(f'Published At: {lowest_view_count_row[\"publishedAt\"]}')\n",
    "    print(f\"View Count: {lowest_view_count_row['viewCount']}\")\n",
    "    print(f\"Like Count: {lowest_view_count_row['likeCount']}\")\n",
    "    print(f\"Comment Count: {lowest_view_count_row['commentCount']}\")\n",
    "    print(f\"Avg Daily Views: {lowest_view_count_row['avgDailyViews']}\")\n",
    "    print(f\"Engagement Rate: {lowest_view_count_row['engagementRate']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Rustin LA stage\n",
      "Published At: 2010-06-26T20:54:32Z\n",
      "View Count: 112\n",
      "Like Count: 5\n",
      "Comment Count: 0\n",
      "Avg Daily Views: 0.02\n",
      "Engagement Rate: 0.04464\n"
     ]
    }
   ],
   "source": [
    "view_lowest('viewCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th percentiles:\n",
      "viewCount         89309.0000\n",
      "likeCount          2298.0000\n",
      "commentCount         70.0000\n",
      "engagementRate        0.0077\n",
      "avgDailyViews       170.6000\n",
      "Name: 0.1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "percentiles = channel_df[['viewCount', 'likeCount', 'commentCount', 'engagementRate', 'avgDailyViews']].quantile(0.1)\n",
    "print(\"10th percentiles:\")\n",
    "print(percentiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take rounded numbers for the filtered dataset (keep the original numbers won't change number of data points). Only the videos which satisfy all the conditions remain in the dataset.\n",
    "\n",
    "We lower the `engagementRate` for channel video dataset this time since lots of videos (music videos and shorts mostly) have a low `engagementRate`. 0.001 is the industry-standardized amount for engagement rate of large channels (around 1-10 million views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_df = channel_df[\n",
    "    (channel_df[\"viewCount\"] >= 90000)\n",
    "    & (channel_df['likeCount'] >= 2300)\n",
    "    & (channel_df['commentCount'] >= 70)\n",
    "    & (channel_df['engagementRate'] >= 0.001)\n",
    "    & (channel_df['avgDailyViews'] >= 170)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14744"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assigning trending labels\n",
    "\n",
    "Similar to the trending dataset, we will also assign `isTrending` and `trendingPercentile`. But we need to assign `isTrending` first. The result is a dataset with `isTrending` either `1` or `0`. \n",
    "\n",
    "The videos with `1` (they are trending) will be separated from videos with `0`. \n",
    "\n",
    "Videos with `1` then get concatenated with trending videos to assign `trendingPercentile` to serve for prediction\n",
    "\n",
    "Videos with `0` will also get a `nonTrendingPercentile` ? With top means (not trending, still significance) and bottom means (not trending, little significance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From trending dataset, we obtained the benchmark for trending videos is as follow\n",
    "```\n",
    "Trending Benchmarks:\n",
    "   isTrending  avgDailyViews  viewCount  likeCount  commentCount\n",
    "0           1      102733.75     397425       9619          1086\n",
    "```\n",
    "The videos which satisfy all these conditions will be marked as trending (1) else (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_benchmarks = {\n",
    "    'avgDailyViews': 102733.75,\n",
    "    'viewCount': 397425,\n",
    "    'likeCount': 9619,\n",
    "    'commentCount': 1086\n",
    "}\n",
    "\n",
    "channel_df['isTrending'] = (\n",
    "    (channel_df['avgDailyViews'] >= trending_benchmarks['avgDailyViews']) &\n",
    "    (channel_df['viewCount'] >= trending_benchmarks['viewCount']) &\n",
    "    (channel_df['likeCount'] >= trending_benchmarks['likeCount']) &\n",
    "    (channel_df['commentCount'] >= trending_benchmarks['commentCount'])\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending_count_df = channel_df[channel_df['isTrending'] == 1]\n",
    "\n",
    "trending_count_df.shape[0] # videos in channel video dataset is marked as trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14744 entries, V0CniCFbxLs to 9Nx849WhPFc\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   publishedAt      14744 non-null  object \n",
      " 1   elapsedDays      14744 non-null  float64\n",
      " 2   title            14744 non-null  object \n",
      " 3   channelTitle     14744 non-null  object \n",
      " 4   category         14744 non-null  object \n",
      " 5   topicCategories  14744 non-null  object \n",
      " 6   duration         14744 non-null  object \n",
      " 7   licensedContent  14744 non-null  bool   \n",
      " 8   viewCount        14744 non-null  int64  \n",
      " 9   likeCount        14744 non-null  int64  \n",
      " 10  commentCount     14744 non-null  int64  \n",
      " 11  avgDailyViews    14744 non-null  float64\n",
      " 12  engagementRate   14744 non-null  float64\n",
      " 13  isTrending       14744 non-null  int32  \n",
      "dtypes: bool(1), float64(3), int32(1), int64(3), object(6)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "channel_df_rep = channel_df[['publishedAt','elapsedDays', 'title', 'channelTitle', \n",
    "                           'category','topicCategories', 'duration', 'licensedContent',\n",
    "                           'viewCount', 'likeCount', 'commentCount', 'avgDailyViews',\n",
    "                           'engagementRate', 'isTrending']]\n",
    "channel_df_rep.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined channel_data JSON saved to C:/Users/TKN/Downloads/New-Youtube-Scraper-v2_turn-in - Copy/data/yt_processed_data.\n"
     ]
    }
   ],
   "source": [
    "output_dir_2 = 'C:/Users/TKN/Downloads/New-Youtube-Scraper-v3/data/yt_processed_data'\n",
    "combined_json = channel_df.to_json(orient=\"index\", force_ascii=False, indent=4)\n",
    "\n",
    "with open(os.path.join(output_dir_2, \"processed_channel_videos.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(combined_json)    \n",
    "print(f\"Combined channel_data JSON saved to {output_dir_2}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
