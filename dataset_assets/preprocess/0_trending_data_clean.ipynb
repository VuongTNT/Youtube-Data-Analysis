{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data exploration on US_trending_videos.json to further clean it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_file_path = 'C:/Users/TKN/Downloads/New-Youtube-Scraper-v3/data/24.11.12_US_trending_videos.json'\n",
    "with open(trending_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    trending_videos = json.load(f)\n",
    "\n",
    "trending_df = pd.DataFrame.from_dict(trending_videos, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 200 entries, mcvLKldPM08 to ccTtAOI_kP4\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   fetchedDate      200 non-null    object \n",
      " 1   publishedAt      200 non-null    object \n",
      " 2   elapsedDays      200 non-null    float64\n",
      " 3   title            200 non-null    object \n",
      " 4   description      200 non-null    object \n",
      " 5   channelTitle     200 non-null    object \n",
      " 6   channelId        200 non-null    object \n",
      " 7   tags             150 non-null    object \n",
      " 8   category         200 non-null    object \n",
      " 9   duration         200 non-null    object \n",
      " 10  licensedContent  200 non-null    bool   \n",
      " 11  viewCount        200 non-null    int64  \n",
      " 12  avgDailyViews    200 non-null    float64\n",
      " 13  likeCount        200 non-null    int64  \n",
      " 14  commentCount     200 non-null    int64  \n",
      " 15  topicCategories  200 non-null    object \n",
      "dtypes: bool(1), float64(2), int64(3), object(10)\n",
      "memory usage: 25.2+ KB\n"
     ]
    }
   ],
   "source": [
    "trending_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop `channelId`, since we no longer need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_df = trending_df.drop(columns=['channelId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop MrBeast rows for a more 'subjective' trending analysis (Since all videos of his all goes on Trending with top-of-the-line of everything, it will be counted as outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 197 entries, mcvLKldPM08 to ccTtAOI_kP4\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   fetchedDate      197 non-null    object \n",
      " 1   publishedAt      197 non-null    object \n",
      " 2   elapsedDays      197 non-null    float64\n",
      " 3   title            197 non-null    object \n",
      " 4   description      197 non-null    object \n",
      " 5   channelTitle     197 non-null    object \n",
      " 6   tags             150 non-null    object \n",
      " 7   category         197 non-null    object \n",
      " 8   duration         197 non-null    object \n",
      " 9   licensedContent  197 non-null    bool   \n",
      " 10  viewCount        197 non-null    int64  \n",
      " 11  avgDailyViews    197 non-null    float64\n",
      " 12  likeCount        197 non-null    int64  \n",
      " 13  commentCount     197 non-null    int64  \n",
      " 14  topicCategories  197 non-null    object \n",
      "dtypes: bool(1), float64(2), int64(3), object(9)\n",
      "memory usage: 23.3+ KB\n"
     ]
    }
   ],
   "source": [
    "trending_df = trending_df[~trending_df['channelTitle'].isin(['MrBeast', 'MrBeast 2'])]\n",
    "\n",
    "trending_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Determine what influences YouTube's Trending page (Trending criteria) and the Trending properties of a video in the US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine trending criteria\n",
    "We want only the videos that satisfy the 'trending' definition:\n",
    "\n",
    "##### Gains a significant amount of attention over a short amount of time.\n",
    "\n",
    "For this, we have the `avgDailyViews` column. It calculates the amount of views gained per day for each videos, by taking the `viewCount` - view count of the video up to the day the data was collected, divided by `elapsedDays` - number of days elapsed from the published day of the video to the day the data was collected (11/12). \n",
    "\n",
    "This number will determine the 'amount of attention' that video received over time. Since the YouTube Data API doesn't facilitate continuous crawling (and our quota is limited), we will assume an uniform distribution of views per day for all videos (by taking the mean number). \n",
    "\n",
    "Doing this will add significance to old videos with massive 'attention amount' in the past (popular). For example, a video posted from 6 years ago with 2 billion views will have an `avgDailyViews` of around 1.1 million. In our case, it will be equivalent to a video posted 1 day ago with 1.1 million views (will be on Trending). \n",
    "\n",
    "This metric will also 'punish' popular past videos as follow. Another example is a video with 300 million views posted from 10 years ago may normally sound popular. However, that video will have an `avgDailyViews` of around 80k. As a result, it may not be on Trending today.\n",
    "\n",
    "This metric, together with `viewCount` will be the most significant when determining which video can be trending (be featured on YouTube's Trending page). Through examining the Trending pages of different countries, Trending videos tend to have a significant `viewCount` over a short time (Trending page mainly have videos that are posted within 1 week from today). The Trending page only considers the video alone to put on Trending, because even channels with a relatively low subscribers and overall video view count can still appear on Trending page.\n",
    "\n",
    "#### Have a good engagement rate\n",
    "\n",
    "`likeCount` and `commentCount` will also be considered to determine whether the video as a good viewer base (good engagement), indicating a genuine interest via `engagementRate`. *Insert formula here*\n",
    "\n",
    "As stated above, statistics related to views will be the most significant when it comes to Trending. Because there are many videos that accumulates their views via. false methods (eg. bots, ads), those will be less likely to represent trending contents. Videos with high engagement are more likely to be discussed, which is vital to trending contents. The industry benchmark for `engagementRate` is around 2%, but we are analyzing US trending videos as of Dec.24, we will adjust it to ensure a fair rate across the dataset (quantile)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New metric to determine cut-off: engagement rate - ensure we only take videos with a relatively good amount of engaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_df['engagementRate'] = ((trending_df['likeCount'] + trending_df['commentCount']) / trending_df['viewCount']).round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`view_stat` function to view the lowest numbers across the vital categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_stats(column_name):\n",
    "    list = sorted(trending_df[column_name].tolist())\n",
    "    print(list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29676, 71511, 95789, 96578, 113637, 121701, 132751, 137043, 139946, 146784]\n",
      "[0, 0, 564, 1322, 1412, 1448, 2243, 2381, 2403, 2504]\n",
      "[0, 0, 60, 155, 166, 210, 220, 285, 300, 373]\n",
      "[0.0, 0.00084, 0.00253, 0.00415, 0.00447, 0.00614, 0.00675, 0.00684, 0.00799, 0.00904]\n",
      "[7932.0, 15740.23, 17741.33, 21616.32, 26639.74, 31071.0, 37357.4, 37960.11, 39428.83, 47480.16]\n"
     ]
    }
   ],
   "source": [
    "view_stats('viewCount')\n",
    "view_stats('likeCount')\n",
    "view_stats('commentCount')\n",
    "view_stats('engagementRate')\n",
    "view_stats('avgDailyViews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`view_lowest` function to view the videos with the lowest interactions (view count, like count, comment count, average daily views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_lowest(column_name):\n",
    "    lowest_view_count_row = trending_df.loc[trending_df[column_name].idxmin()]\n",
    "    print(f\"Title: {lowest_view_count_row['title']}\")\n",
    "    print(f'Published At: {lowest_view_count_row[\"publishedAt\"]}')\n",
    "    print(f\"View Count: {lowest_view_count_row['viewCount']}\")\n",
    "    print(f\"Like Count: {lowest_view_count_row['likeCount']}\")\n",
    "    print(f\"Comment Count: {lowest_view_count_row['commentCount']}\")\n",
    "    print(f\"Avg Daily Views: {lowest_view_count_row['avgDailyViews']}\")\n",
    "    print(f\"Engagement Rate: {lowest_view_count_row['engagementRate']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_lowest('viewCount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cut-off criteria\n",
    "\n",
    "To further filter the dataset and ensure only the most relevant videos qualify as trending, we will use percentile-based cut-offs for key metrics. Specifically, we will eliminate the bottom 20th percentile of videos based on the following features `'viewCount', 'likeCount', 'commentCount', 'engagementRate', 'avgDailyViews'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th percentiles:\n",
      "viewCount         390311.600000\n",
      "likeCount           8898.800000\n",
      "commentCount         972.000000\n",
      "engagementRate         0.016104\n",
      "avgDailyViews     117688.160000\n",
      "Name: 0.2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "percentiles = trending_df[['viewCount', 'likeCount', 'commentCount', 'engagementRate', 'avgDailyViews']].quantile(0.2)\n",
    "print(\"20th percentiles:\")\n",
    "print(percentiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take rounded numbers for the filtered dataset (keep the original numbers won't change number of data points). Only the videos which satisfy all the conditions remain in the dataset, ensuring that all videos are suitable representations of trending topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_df = trending_df[\n",
    "    (trending_df[\"viewCount\"] >= 390000)\n",
    "    & (trending_df['likeCount'] >= 9000)\n",
    "    & (trending_df['commentCount'] >= 1000)\n",
    "    & (trending_df['engagementRate'] >= 0.015)\n",
    "    & (trending_df['avgDailyViews'] >= 100000)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assigning trending labels\n",
    "\n",
    "We will assign 1 more property for the dataset (to serve the prediction part)\n",
    "\n",
    "- `isTrending`: Determine whether a certain video will be featured on the Trending page. `1` for yes, `0` otherwise. All videos in this dataset will be marked as `1` (since they're all featured)\n",
    "\n",
    "- The videos with the lowest satisfied criteria will be the benchmark to determine whether a video from the channel dataset will be on Trending.\n",
    "\n",
    "#### Depreciated\n",
    "- `trendingPercentile`: If a video is on Trending, which percentile will it belong. We will order the dataset by `avgDailyViews`, then `viewCount`, `likeCount` and `commentCount` (the major indicator of Trending videos), bin the dataset into 10 parts, then assign 10 different percentiles, from `0.05` (top 95%) to `0.95` (top 5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_df['isTrending'] = 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trending Benchmarks:\n",
      "   isTrending  avgDailyViews  viewCount  likeCount  commentCount\n",
      "0           1      102733.75     397425       9619          1086\n"
     ]
    }
   ],
   "source": [
    "benchmarks = trending_df.groupby('isTrending').agg({\n",
    "    'avgDailyViews': 'min',\n",
    "    'viewCount': 'min',\n",
    "    'likeCount': 'min',\n",
    "    'commentCount': 'min'\n",
    "}).reset_index()\n",
    "\n",
    "print(\"Trending Benchmarks:\")\n",
    "print(benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 108 entries, mcvLKldPM08 to LlBzNiQeeXM\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   publishedAt      108 non-null    object \n",
      " 1   elapsedDays      108 non-null    float64\n",
      " 2   title            108 non-null    object \n",
      " 3   channelTitle     108 non-null    object \n",
      " 4   category         108 non-null    object \n",
      " 5   topicCategories  108 non-null    object \n",
      " 6   duration         108 non-null    object \n",
      " 7   licensedContent  108 non-null    bool   \n",
      " 8   viewCount        108 non-null    int64  \n",
      " 9   likeCount        108 non-null    int64  \n",
      " 10  commentCount     108 non-null    int64  \n",
      " 11  avgDailyViews    108 non-null    float64\n",
      " 12  engagementRate   108 non-null    float64\n",
      " 13  isTrending       108 non-null    int64  \n",
      "dtypes: bool(1), float64(3), int64(4), object(6)\n",
      "memory usage: 11.9+ KB\n"
     ]
    }
   ],
   "source": [
    "trending_df_rep = trending_df[['publishedAt','elapsedDays', 'title', 'channelTitle', \n",
    "                           'category','topicCategories', 'duration', 'licensedContent',\n",
    "                           'viewCount', 'likeCount', 'commentCount', 'avgDailyViews',\n",
    "                           'engagementRate', 'isTrending']]\n",
    "trending_df_rep.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined channel_data JSON saved to C:/Users/TKN/Downloads/New-Youtube-Scraper-v2_turn-in - Copy/data/yt_processed_data.\n"
     ]
    }
   ],
   "source": [
    "output_dir_2 = 'C:/Users/TKN/Downloads/New-Youtube-Scraper-v3/data/yt_processed_data'\n",
    "combined_json = trending_df.to_json(orient=\"index\", force_ascii=False, indent=4)\n",
    "\n",
    "with open(os.path.join(output_dir_2, \"processed_US_trending_data.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(combined_json)    \n",
    "print(f\"Combined channel_data JSON saved to {output_dir_2}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
